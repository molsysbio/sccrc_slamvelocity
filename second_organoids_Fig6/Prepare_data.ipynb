{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "This notebook carries out the following steps sequentially:\n",
    "- load data from cellranger (adata.X, GEX-matrix), the SLAM count matrices (new/old, i.e. labeled/unlabeled), and un-/spliced count matrices generated by velocyto\n",
    "- demultiplexing (from HTOdemux in Seurat) / annotation of sample identity (donor) and condition (perturbation). Throws out doublets and negatives from demuxing.\n",
    "- preprocess the data:\n",
    "    - (Filtering was done in previous steps / before demultiplexing)\n",
    "    - Normalization of X and the layers, log-normalization\n",
    "    - scoring of gene sigantures / cell cycle\n",
    "    - cell cycle regression (depending on user settings. We produced datasets both with and without cc regression).\n",
    "- preparation for visualization\n",
    "    - pca\n",
    "    - KNN\n",
    "    - umap (based on top 2000 HVGs)\n",
    "    - diffmap (based on top 2000 HVGs)\n",
    "- steady state models of both SLAM and RNA velocity + velocity graph (embeddings)\n",
    "- adding of progeny scores from external tool (PROGENY in R)\n",
    "- division into seperate donor datasets, then saving them as .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports and Settings (run these first!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T08:48:39.022293Z",
     "start_time": "2021-01-28T08:48:33.243162Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scvelo 0.1.16.dev32+c00a55e.dirty (python 3.6.6) on 2021-01-28 09:48.\n"
     ]
    }
   ],
   "source": [
    "import scvelo as scv  # 0.1.16.dev32\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.backends.backend_pdf\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "scv.logging.print_version()\n",
    "scv.settings.set_figure_params(\n",
    "    'scvelo', dpi_save=100, dpi=80, transparent=True)\n",
    "scv.settings.verbosity = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T08:48:39.069857Z",
     "start_time": "2021-01-28T08:48:39.055790Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Please adapt your paths accordingly (Warning: requires ~50GB space)\n",
    "data_path='G:/data/scSLAMseq/revision/'\n",
    "signatures_path='G:/data/scrnaseq_signature_collection/'\n",
    "libraries = ['AB', 'CE', 'DF']\n",
    "donors=['B2-040', 'C2-019', 'OT227', 'OT302', 'P009T', 'P013T']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add layers, annotate identities, split into donors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Input:\n",
    "- libraries: `data_path+'cellranger_output_MM_ML_revision_'+library+'/outs/filtered_feature_bc_matrix.h5'`\n",
    "- SLAM layers: `data_path+'slam_MM_ML_'+library+'/SLAM_PIPELINE/'+time+'_matrix'`\n",
    "- velocyto looms: `data_path+'looms/'+library+'_loom/'+library+'.loom'`\n",
    "- annotation file from demuxing and filtering (seurat): `data_path+'annotation.tsv'`\n",
    "\n",
    "Output: `data_path+'by_donors/SLAMv2_'+donor+'.h5'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T10:24:36.904913Z",
     "start_time": "2020-12-08T10:24:36.880100Z"
    },
    "code_folding": [
     1,
     24,
     58
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define functions:\n",
    "\n",
    "# This function loads SLAM layers and libraries, aligns gene and cell names (alphabetically) and merges them together\n",
    "def load_and_sparse_add_SLAM(library='CE'):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    adata = sc.read_10x_h5(data_path+'cellranger_output_MM_ML_revision_'+library+'/outs/filtered_feature_bc_matrix.h5')\n",
    "    adata.var_names_make_unique()\n",
    "    for time in ['new', 'old']:\n",
    "        bdata=sc.read_10x_mtx(data_path+'slam_MM_ML_'+library+'/SLAM_PIPELINE/'+time+'_matrix')\n",
    "        bdata.var_names_make_unique()\n",
    "        \n",
    "        d = {j: np.where(adata.var_names==gene)[0][0] for j, gene in enumerate(tqdm_notebook(bdata.var_names))}  # maps bdata vars to adata vars indices\n",
    "\n",
    "        # map indices\n",
    "        new_indices = []\n",
    "        for i in tqdm_notebook(range(len(bdata.X.indptr)-1)):\n",
    "            new_indices.extend(list(map(d.get, bdata.X.indices[bdata.X.indptr[i]:bdata.X.indptr[i+1]])))\n",
    "\n",
    "        # cells are already aligned it seems\n",
    "        assert np.sum(bdata.obs_names != adata.obs_names)==0\n",
    "\n",
    "        M=csr_matrix((bdata.X.data, new_indices, bdata.X.indptr), adata.X.shape)\n",
    "        adata.layers[time]=M\n",
    "    return adata\n",
    "\n",
    "# Adds the u & s layers from velocyto for \"classical\" RNA velocity\n",
    "def add_real_loom(library, adata=None):\n",
    "    adata = sc.read_10x_h5(data_path+'cellranger_output_MM_ML_revision_'+library+'/outs/filtered_feature_bc_matrix.h5') if adata is None else adata\n",
    "    bdata = scv.read_loom(data_path+'looms/'+library+'_loom/'+library+'.loom')\n",
    "    \n",
    "    # clean names\n",
    "    adata.obs_names = [x.split('-')[0] for x in adata.obs_names]\n",
    "    bdata.obs_names = [x.split(':')[-1] for x in bdata.obs_names]\n",
    "    adata.var_names_make_unique()\n",
    "    bdata.var_names_make_unique()\n",
    "\n",
    "    # subset to same genes and cells\n",
    "    bdata = bdata[np.isin(bdata.obs_names, adata.obs_names)].copy()\n",
    "    bdata = bdata[:, np.isin(bdata.var_names, adata.var_names)].copy()\n",
    "    adata = adata[np.isin(adata.obs_names, bdata.obs_names)].copy()\n",
    "    adata = adata[:, np.isin(adata.var_names, bdata.var_names)].copy()\n",
    "    \n",
    "    assert adata.n_obs==bdata.n_obs\n",
    "    assert adata.n_vars==bdata.n_vars\n",
    "    \n",
    "    # align genes and cells (alphabetically sorted)\n",
    "    av=np.argsort(adata.var_names)\n",
    "    ao=np.argsort(adata.obs_names)\n",
    "    adata = adata[ao,av].copy()\n",
    "    bv=np.argsort(bdata.var_names)\n",
    "    bo=np.argsort(bdata.obs_names)\n",
    "    bdata = bdata[bo,bv].copy()\n",
    "    \n",
    "    # add layers from loom\n",
    "    adata.layers['real_unspliced']=bdata.layers['unspliced']\n",
    "    adata.layers['real_spliced']=bdata.layers['spliced']\n",
    "    adata.layers['real_ambiguous']=bdata.layers['ambiguous']\n",
    "    return adata\n",
    "\n",
    "# Applies filtering and demultiplexing (done in Seurat)\n",
    "def annotate_identity(library, adata = None):\n",
    "    # load\n",
    "    adata = sc.read_10x_h5(data_path+'cellranger_output_MM_ML_revision_'+library+'/outs/filtered_feature_bc_matrix.h5') if adata is None else adata\n",
    "    adata.var_names_make_unique()\n",
    "    adata.obs_names = [x.split('-')[0] for x in adata.obs_names]\n",
    "\n",
    "    # add annotation\n",
    "    tab = pd.read_csv(data_path+'annotation.tsv', sep='\\t')\n",
    "    subtab=tab[tab.cell.str.startswith(library)]\n",
    "    subtab.cell=subtab.cell.str.replace(library+'_', '')\n",
    "    subtab['library'] = library\n",
    "    subtab = subtab.set_index('cell')\n",
    "    subtab = subtab[np.isin(subtab.index, adata.obs_names)]  # subset obs\n",
    "    adata.obs=pd.concat([adata.obs, subtab], axis=1, join='outer')\n",
    "\n",
    "    # throw out cell that nils filtered and hence did not annotate\n",
    "    adata = adata[~pd.isna(adata.obs.library)]\n",
    "\n",
    "    # throw out Doublets and negatives from HTO demux\n",
    "    adata = adata[adata.obs['HTO_classification.global']=='Singlet'].copy()\n",
    "    \n",
    "    # annotate ribosomal\n",
    "    ribo_genes = np.logical_or(adata.var_names.str.startswith('RPS'), adata.var_names.str.startswith('RPL'))\n",
    "    adata.obs['percent_ribosomal'] = np.sum(adata[:, ribo_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n",
    "    \n",
    "    return adata\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T10:51:17.602431Z",
     "start_time": "2020-12-08T10:24:38.238734Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(data_path+'by_donors/').mkdir(parents=True, exist_ok=True)\n",
    "# Add SLAM and velocyto layers, apply demux and filtering from Seurat, split libraries into donors\n",
    "for library in tqdm_notebook(libraries):\n",
    "    adata = load_and_sparse_add_SLAM(library)\n",
    "    print(vars(adata.X))  # this is for control\n",
    "    adata = add_real_loom(library, adata)\n",
    "    print(vars(adata.X))\n",
    "    adata = annotate_identity(library, adata)\n",
    "    print(vars(adata.X))\n",
    "    for donor in pd.unique(adata.obs.organoid):\n",
    "        adata[adata.obs.organoid==donor].write(data_path+'by_donors/SLAMv2_'+donor+'.h5')\n",
    "        print(vars(adata.X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Signature Scoring, Preprocessing & SS velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "input: \n",
    "- `data_path+'by_donors/SLAMv2_'+donor+'.h5'` from previous step.\n",
    "- Signatures (found in the respective references)\n",
    "\n",
    "output: `data_path+'/by_donors/processed/SLAMv2_'+donor+'_processed(_ccreg).h5'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T11:19:56.490490Z",
     "start_time": "2020-12-09T11:19:56.463562Z"
    },
    "code_folding": [
     1,
     9,
     55,
     73,
     89,
     110
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define functions:\n",
    "\n",
    "# normalize and log transform GEX matrix and layers\n",
    "def prepare(adata):\n",
    "    sc.pp.normalize_total(adata)  # normalize X\n",
    "    scv.pp.normalize_per_cell(adata, layers=['old', 'new', 'real_unspliced', 'real_spliced'])\n",
    "    scv.pp.log1p(adata)  # enforce normalize X\n",
    "    return adata\n",
    "\n",
    "# Annotate data with Cell cycle score (+ cc regression if selected), ISC signatures, \n",
    "# Custom Signatures (Florian Uhlitz, YAP), Hallmark\n",
    "def annotate(adata, regress_cc=False):\n",
    "    # Annotations\n",
    "    # single genes of interest from Markus Morkel\n",
    "    single_genes = ['LGR5', 'OLFM4', 'TFF3', 'FABP1', 'EPHB2', 'AXIN1', 'AXIN2', 'EGR1']\n",
    "    \n",
    "    # Locally set silent, cuz it's annoying :)\n",
    "    k = sc.settings.verbosity\n",
    "    sc.settings.verbosity = 0\n",
    "\n",
    "    # cc score, get it from https://raw.githubusercontent.com/theislab/scanpy_usage/master/180209_cell_cycle/data/regev_lab_cell_cycle_genes.txt\n",
    "    cell_cycle_genes = [x.strip() for x in open(signatures_path+'cell_cycle_genes/regev_lab_cell_cycle_genes.txt')]\n",
    "    s_genes = cell_cycle_genes[:43]\n",
    "    g2m_genes = cell_cycle_genes[43:]\n",
    "    cell_cycle_genes = [x for x in cell_cycle_genes if x in adata.var_names]\n",
    "    adata.obs_names_make_unique()\n",
    "    sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)\n",
    "    if regress_cc:\n",
    "        sc.pp.regress_out(adata, ['S_score', 'G2M_score'])\n",
    "\n",
    "    # Stem sig from curated lists, see references\n",
    "    tab=pd.read_excel(signatures_path+'cell_type_markers/CRC-related_stem_cell_signatures.xlsx', header=0)\n",
    "    tab = tab.drop(0)\n",
    "    sigs = {'Stem_'+x: list(tab[x][~pd.isna(tab[x])].values) for x in tab.columns}\n",
    "    for ct in ['Stem_Lgr5_ISC-Munoz', 'Stem_Lgr5_ISC-Merlos']:\n",
    "        sc.tl.score_genes(adata, sigs[ct], score_name=ct)\n",
    "\n",
    "    # Flo sig, from this publication\n",
    "    tab=pd.read_excel(signatures_path+'cell_type_markers/colonoid_cancer_uhlitz_markers_revised.xlsx', header=1, sheet_name=2)\n",
    "    flo_sigs={x: list(tab[tab['cell_type_epi']==x].gene.values) for x in pd.unique(tab['cell_type_epi'])}\n",
    "    for ct in ['Stem', 'Enterocytes 1', 'Enterocytes 2', 'TC1', 'TC2', 'TC3', 'TC4', 'Goblet', 'Stem/TA 1', 'Stem/TA 2', 'Stem/TA 3']:  #flo_sigs.keys():\n",
    "        sc.tl.score_genes(adata, flo_sigs[ct], score_name=ct)\n",
    "    \n",
    "    # Hallmarks, http://www.gsea-msigdb.org/gsea/msigdb/collections.jsp\n",
    "    tab=pd.read_csv(signatures_path + 'msigdb/hallmark/h.all.v6.2.symbols.gmt', sep='\\t', index_col=0, header=None).drop(1, axis=1).T\n",
    "    hallsigs={hallmark : tab[hallmark][~pd.isna(tab[hallmark])].values for hallmark in tab.columns}\n",
    "    for hm in ['HALLMARK_DNA_REPAIR', 'HALLMARK_WNT_BETA_CATENIN_SIGNALING']:\n",
    "        sc.tl.score_genes(adata, hallsigs[hm], score_name=hm)\n",
    "        \n",
    "    # YAP targets (custom, curated)\n",
    "    yap_targets = ['CTGF', 'GGTA1', 'WWC2', 'ANXA8', 'CLU', 'CXCL16', 'IL33', 'LY6A', 'LY6C1', 'MSLN', 'TNFRSF12A', 'CTGF', 'GGTA1', 'WWC2', 'ANXA5', 'TACSTD2', 'ANXA10', 'EREG', 'IL33', 'ANXA1', 'ANXA3']\n",
    "    sc.tl.score_genes(adata, yap_targets, score_name='YAP_targets')\n",
    "\n",
    "    sc.settings.verbosity = k\n",
    "    return adata\n",
    "\n",
    "# PCA, KNN, and UMAP/diffmap based on top 2000 HVGs\n",
    "def embedd(adata):\n",
    "    scv.pp.pca(adata)\n",
    "    scv.pp.neighbors(adata)\n",
    "\n",
    "    # umap on 2000 HVGs\n",
    "    bdata=scv.pp.filter_genes_dispersion(adata, n_top_genes=2000, copy=True)\n",
    "    scv.pp.pca(bdata)\n",
    "    scv.pp.neighbors(bdata)\n",
    "    scv.tl.umap(bdata)\n",
    "    scv.tl.diffmap(bdata)\n",
    "    adata.obsm['X_umap']=bdata.obsm['X_umap']\n",
    "    adata.obsm['X_diffmap']=bdata.obsm['X_diffmap']\n",
    "    del bdata\n",
    "    return adata\n",
    "\n",
    "# Make the KNN disjoint w.r.t. perturbations. Since the different perturbations came from different replicates, \n",
    "# we would mask out variation when applying the moment estimation on a complete KNN graph.\n",
    "# See methods for details.\n",
    "def restrict_KNN(adata):\n",
    "    # restrict KNN connectivities to within perturbations only\n",
    "    from scipy.sparse import csr_matrix\n",
    "    adata = adata[np.argsort(adata.obs.perturbation)].copy()  # sort by perturbation\n",
    "    A=adata.obsp['connectivities'].A\n",
    "    for pert in pd.unique(adata.obs.perturbation):\n",
    "        # identify nodes\n",
    "        a=np.where(adata.obs.perturbation==pert)[0]\n",
    "        b=np.where(adata.obs.perturbation!=pert)[0]\n",
    "        # remove edges to different perturbations\n",
    "        A[np.min(a):np.max(a), b]=0\n",
    "        A[b, np.min(a):np.max(a)]=0\n",
    "    adata.obsp['connectivities'] = csr_matrix(A)\n",
    "    return adata\n",
    "\n",
    "# Compute steady state velocities, velocity graphs and velocity embeddings.\n",
    "def velocity(adata):\n",
    "    adata = restrict_KNN(adata)\n",
    "    \n",
    "    # SLAM\n",
    "    adata.layers['unspliced']=adata.layers['new']\n",
    "    adata.layers['spliced']=adata.layers['old']\n",
    "    scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "    scv.tl.velocity(adata, vkey='SLAM_velocity')\n",
    "    scv.tl.velocity_graph(adata, vkey='SLAM_velocity')\n",
    "    scv.tl.velocity_embedding(adata, basis='umap', vkey='SLAM_velocity')\n",
    "    \n",
    "    # real un/spliced\n",
    "    adata.layers['unspliced']=adata.layers['real_unspliced']\n",
    "    adata.layers['spliced']=adata.layers['real_spliced']\n",
    "    scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "    scv.tl.velocity(adata, vkey='real_velocity')\n",
    "    scv.tl.velocity_graph(adata, vkey='real_velocity')\n",
    "    scv.tl.velocity_embedding(adata, basis='umap', vkey='real_velocity')\n",
    "    return adata\n",
    "\n",
    "# Add the result from progeny (R, externally called)\n",
    "def add_progeny(adata, donor):\n",
    "    tab=pd.read_csv(data_path+'progeny/'+donor+'_progeny.csv', index_col=1)\n",
    "    tab=tab.drop(tab.columns[0], axis=1)\n",
    "    Z=[]\n",
    "    for p in pd.unique(tab.Pathway):\n",
    "        Z.append(tab[tab.Pathway==p].Activity.values)\n",
    "    Z=np.array(Z)\n",
    "    progeny_act = pd.DataFrame(Z.T, tab[tab.Pathway==p].index, columns=[x+'_progeny' for x in pd.unique(tab.Pathway)])\n",
    "    adata.obs=pd.concat([adata.obs, progeny_act], axis=1)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T11:46:32.939648Z",
     "start_time": "2020-12-09T11:19:59.250037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# options\n",
    "ccreg = True  # whether or not to regress out cell cycle (default: True)\n",
    "\n",
    "# preparations\n",
    "from pathlib import Path\n",
    "Path(data_path+'by_donors/processed/').mkdir(parents=True, exist_ok=True)\n",
    "ccr_suffix = '_ccreg' if ccreg else ''\n",
    "\n",
    "# Process all samples\n",
    "for donor in tqdm_notebook(donors):\n",
    "    scv.settings.verbosity = 0\n",
    "    adata = sc.read(data_path+'by_donors/SLAMv2_'+donor+'.h5')\n",
    "    adata = prepare(adata)\n",
    "    adata = annotate(adata, regress_cc=ccreg)\n",
    "    adata = add_progeny(adata, donor)\n",
    "    adata = embedd(adata)\n",
    "    adata = velocity(adata)\n",
    "    adata.obs.rename(columns={\"Stem/TA 1\": \"Stem_TA 1\", \"Stem/TA 2\": \"Stem_TA 2\", \"Stem/TA 3\": \"Stem_TA 3\"}, inplace=True)  # \"/\" throws error in saved .h5, so we rename these to \"_\"\n",
    "    adata.write(data_path+'/by_donors/processed/SLAMv2_'+donor+'_processed'+ccr_suffix+'.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "560.99px",
    "left": "1763.33px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
